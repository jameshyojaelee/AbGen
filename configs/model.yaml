# Transformer model defaults.
vocab_size: 25  # 4 specials + 21 amino acid tokens
d_model: 384
nhead: 6
num_layers: 3
dim_feedforward: 1536
dropout: 0.1
max_position_embeddings: 1024
encoder_type: transformer  # transformer | mamba
use_rope: true
norm_type: rmsnorm  # layernorm | rmsnorm
activation: swiglu  # relu | gelu | swiglu
# Mamba / SSM parameters (used when encoder_type=mamba)
ssm_d_state: 16
ssm_d_conv: 4
ssm_expand: 2
ssm_dt_rank: auto
liability_keys:
  - nglyc
  - deamidation
  - isomerization
  - oxidation
  - free_cysteines
task_weights:
  mlm: 1.0
  cls: 1.0
  reg: 1.0
